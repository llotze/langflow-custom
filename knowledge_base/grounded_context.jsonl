{"category": "jigsawstack", "name": "JigsawStackVOCR", "display_name": "VOCR", "description": "Extract data from any document type in a consistent structure with fine-tuned         vLLMs for the highest accuracy", "base_classes": ["Data"], "inputs": [{"name": "api_key", "display_name": "JigsawStack API Key", "type": "str", "info": "Your JigsawStack API key for authentication", "required": true}, {"name": "file_store_key", "display_name": "File Store Key", "type": "str", "info": "The key used to store the image on Jigsawstack File Storage. Not required if url is specified.", "required": false}, {"name": "page_range_end", "display_name": "Page Range End", "type": "int", "info": "Page range end limit for the document. If not specified, all pages will be processed.", "required": false}, {"name": "page_range_start", "display_name": "Page Range", "type": "int", "info": "Page range start limit for the document. If not specified, all pages will be processed.", "required": false}, {"name": "prompts", "display_name": "Prompts", "type": "str", "info": "The prompts used to describe the image. Default prompt is Describe the image in detail.                 You can pass a list of comma-separated prompts to extract different information from the image.", "required": false}, {"name": "url", "display_name": "URL", "type": "str", "info": "The image or document url. Not required if file_store_key is specified.", "required": false}]}
{"category": "groq", "name": "GroqModel", "display_name": "Groq", "description": "Generate text using Groq.", "base_classes": ["LanguageModel", "Message"], "inputs": [{"name": "api_key", "display_name": "Groq API Key", "type": "str", "info": "API key for the Groq API.", "required": false}, {"name": "base_url", "display_name": "Groq API Base", "type": "str", "info": "Base URL path for API requests, leave blank if not using a proxy or service emulator.", "required": false}, {"name": "input_value", "display_name": "Input", "type": "str", "info": "", "required": false}, {"name": "max_tokens", "display_name": "Max Output Tokens", "type": "int", "info": "The maximum number of tokens to generate.", "required": false}, {"name": "model_name", "display_name": "Model", "type": "str", "info": "The name of the model to use.", "required": false}, {"name": "n", "display_name": "N", "type": "int", "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.", "required": false}, {"name": "stream", "display_name": "Stream", "type": "bool", "info": "Stream the response from the model. Streaming works only in Chat.", "required": false}, {"name": "system_message", "display_name": "System Message", "type": "str", "info": "System message to pass to the model.", "required": false}, {"name": "temperature", "display_name": "Temperature", "type": "slider", "info": "Run inference with this temperature. Must by in the closed interval [0.0, 1.0].", "required": false}, {"name": "tool_model_enabled", "display_name": "Enable Tool Models", "type": "bool", "info": "Select if you want to use models that can work with tools. If yes, only those models will be shown.", "required": false}]}
{"category": "vertexai", "name": "VertexAiModel", "display_name": "Vertex AI", "description": "Generate text using Vertex AI LLMs.", "base_classes": ["LanguageModel", "Message"], "inputs": [{"name": "credentials", "display_name": "Credentials", "type": "file", "info": "JSON credentials file. Leave empty to fallback to environment variables", "required": false}, {"name": "input_value", "display_name": "Input", "type": "str", "info": "", "required": false}, {"name": "location", "display_name": "Location", "type": "str", "info": "", "required": false}, {"name": "max_output_tokens", "display_name": "Max Output Tokens", "type": "int", "info": "", "required": false}, {"name": "max_retries", "display_name": "Max Retries", "type": "int", "info": "", "required": false}, {"name": "model_name", "display_name": "Model Name", "type": "str", "info": "", "required": false}, {"name": "project", "display_name": "Project", "type": "str", "info": "The project ID.", "required": false}, {"name": "stream", "display_name": "Stream", "type": "bool", "info": "Stream the response from the model. Streaming works only in Chat.", "required": false}, {"name": "system_message", "display_name": "System Message", "type": "str", "info": "System message to pass to the model.", "required": false}, {"name": "temperature", "display_name": "Temperature", "type": "float", "info": "", "required": false}, {"name": "top_k", "display_name": "Top K", "type": "int", "info": "", "required": false}, {"name": "top_p", "display_name": "Top P", "type": "float", "info": "", "required": false}, {"name": "verbose", "display_name": "Verbose", "type": "bool", "info": "", "required": false}]}
{"category": "huggingface", "name": "HuggingFaceModel", "display_name": "Hugging Face", "description": "Generate text using Hugging Face Inference APIs.", "base_classes": ["LanguageModel", "Message"], "inputs": [{"name": "custom_model", "display_name": "Custom Model ID", "type": "str", "info": "Enter a custom model ID from Hugging Face Hub", "required": true}, {"name": "huggingfacehub_api_token", "display_name": "HuggingFace HubAPI Token", "type": "str", "info": "", "required": true}, {"name": "inference_endpoint", "display_name": "Inference Endpoint", "type": "str", "info": "Custom inference endpoint URL.", "required": true}, {"name": "input_value", "display_name": "Input", "type": "str", "info": "", "required": false}, {"name": "max_new_tokens", "display_name": "Max New Tokens", "type": "int", "info": "Maximum number of generated tokens", "required": false}, {"name": "model_id", "display_name": "Model ID", "type": "str", "info": "Select a model from Hugging Face Hub", "required": true}, {"name": "model_kwargs", "display_name": "Model Keyword Arguments", "type": "dict", "info": "", "required": false}, {"name": "repetition_penalty", "display_name": "Repetition Penalty", "type": "float", "info": "The parameter for repetition penalty. 1.0 means no penalty.", "required": false}, {"name": "retry_attempts", "display_name": "Retry Attempts", "type": "int", "info": "", "required": false}, {"name": "stream", "display_name": "Stream", "type": "bool", "info": "Stream the response from the model. Streaming works only in Chat.", "required": false}, {"name": "system_message", "display_name": "System Message", "type": "str", "info": "System message to pass to the model.", "required": false}, {"name": "task", "display_name": "Task", "type": "str", "info": "The task to call the model with. Should be a task that returns `generated_text` or `summary_text`.", "required": false}, {"name": "temperature", "display_name": "Temperature", "type": "slider", "info": "The value used to module the logits distribution", "required": false}, {"name": "top_k", "display_name": "Top K", "type": "int", "info": "The number of highest probability vocabulary tokens to keep for top-k-filtering", "required": false}, {"name": "top_p", "display_name": "Top P", "type": "float", "info": "If set to < 1, only the smallest set of most probable tokens with probabilities that add up to `top_p` or higher are kept for generation", "required": false}, {"name": "typical_p", "display_name": "Typical P", "type": "float", "info": "Typical Decoding mass.", "required": false}]}
{"category": "azure", "name": "AzureOpenAIModel", "display_name": "Azure OpenAI", "description": "Generate text using Azure OpenAI LLMs.", "base_classes": ["LanguageModel", "Message"], "inputs": [{"name": "api_key", "display_name": "Azure Chat OpenAI API Key", "type": "str", "info": "", "required": true}, {"name": "api_version", "display_name": "API Version", "type": "str", "info": "", "required": false}, {"name": "azure_deployment", "display_name": "Deployment Name", "type": "str", "info": "", "required": true}, {"name": "azure_endpoint", "display_name": "Azure Endpoint", "type": "str", "info": "Your Azure endpoint, including the resource. Example: `https://example-resource.azure.openai.com/`", "required": true}, {"name": "input_value", "display_name": "Input", "type": "str", "info": "", "required": false}, {"name": "max_tokens", "display_name": "Max Tokens", "type": "int", "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.", "required": false}, {"name": "stream", "display_name": "Stream", "type": "bool", "info": "Stream the response from the model. Streaming works only in Chat.", "required": false}, {"name": "system_message", "display_name": "System Message", "type": "str", "info": "System message to pass to the model.", "required": false}, {"name": "temperature", "display_name": "Temperature", "type": "slider", "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.", "required": false}]}
{"category": "google", "name": "GoogleDriveComponent", "display_name": "Google Drive Loader", "description": "Loads documents from Google Drive using provided credentials.", "base_classes": ["Data"], "inputs": [{"name": "document_id", "display_name": "Document ID", "type": "str", "info": "Single Google Drive document ID", "required": true}, {"name": "json_string", "display_name": "JSON String of the Service Account Token", "type": "str", "info": "JSON string containing OAuth 2.0 access token information for service account access", "required": true}]}
{"category": "anthropic", "name": "AnthropicModel", "display_name": "Anthropic", "description": "Generate text using Anthropic's Messages API and models.", "base_classes": ["LanguageModel", "Message"], "inputs": [{"name": "api_key", "display_name": "Anthropic API Key", "type": "str", "info": "Your Anthropic API key.", "required": true}, {"name": "base_url", "display_name": "Anthropic API URL", "type": "str", "info": "Endpoint of the Anthropic API. Defaults to 'https://api.anthropic.com' if not specified.", "required": false}, {"name": "input_value", "display_name": "Input", "type": "str", "info": "", "required": false}, {"name": "max_tokens", "display_name": "Max Tokens", "type": "int", "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.", "required": false}, {"name": "model_name", "display_name": "Model Name", "type": "str", "info": "", "required": false}, {"name": "stream", "display_name": "Stream", "type": "bool", "info": "Stream the response from the model. Streaming works only in Chat.", "required": false}, {"name": "system_message", "display_name": "System Message", "type": "str", "info": "System message to pass to the model.", "required": false}, {"name": "temperature", "display_name": "Temperature", "type": "slider", "info": "Run inference with this temperature. Must by in the closed interval [0.0, 1.0].", "required": false}, {"name": "tool_model_enabled", "display_name": "Enable Tool Models", "type": "bool", "info": "Select if you want to use models that can work with tools. If yes, only those models will be shown.", "required": false}]}
{"category": "cohere", "name": "CohereModel", "display_name": "Cohere Language Models", "description": "Generate text using Cohere LLMs.", "base_classes": ["LanguageModel", "Message"], "inputs": [{"name": "cohere_api_key", "display_name": "Cohere API Key", "type": "str", "info": "The Cohere API Key to use for the Cohere model.", "required": true}, {"name": "input_value", "display_name": "Input", "type": "str", "info": "", "required": false}, {"name": "stream", "display_name": "Stream", "type": "bool", "info": "Stream the response from the model. Streaming works only in Chat.", "required": false}, {"name": "system_message", "display_name": "System Message", "type": "str", "info": "System message to pass to the model.", "required": false}, {"name": "temperature", "display_name": "Temperature", "type": "slider", "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.", "required": false}]}
{"category": "google", "name": "GoogleDriveSearchComponent", "display_name": "Google Drive Search", "description": "Searches Google Drive files using provided credentials and query parameters.", "base_classes": ["Data", "Text"], "inputs": [{"name": "query_item", "display_name": "Query Item", "type": "str", "info": "The field to query.", "required": true}, {"name": "query_string", "display_name": "Query String", "type": "str", "info": "The query string used for searching. You can edit this manually.", "required": false}, {"name": "search_term", "display_name": "Search Term", "type": "str", "info": "The value to search for in the specified query item.", "required": true}, {"name": "token_string", "display_name": "Token String", "type": "str", "info": "JSON string containing OAuth 2.0 access token information for service account access", "required": true}, {"name": "valid_operator", "display_name": "Valid Operator", "type": "str", "info": "Operator to use in the query.", "required": true}]}
{"category": "google", "name": "GoogleGenerativeAIModel", "display_name": "Google Generative AI", "description": "Generate text using Google Generative AI.", "base_classes": ["LanguageModel", "Message"], "inputs": [{"name": "api_key", "display_name": "Google API Key", "type": "str", "info": "The Google API Key to use for the Google Generative AI.", "required": true}, {"name": "input_value", "display_name": "Input", "type": "str", "info": "", "required": false}, {"name": "max_output_tokens", "display_name": "Max Output Tokens", "type": "int", "info": "The maximum number of tokens to generate.", "required": false}, {"name": "model_name", "display_name": "Model", "type": "str", "info": "The name of the model to use.", "required": false}, {"name": "n", "display_name": "N", "type": "int", "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.", "required": false}, {"name": "stream", "display_name": "Stream", "type": "bool", "info": "Stream the response from the model. Streaming works only in Chat.", "required": false}, {"name": "system_message", "display_name": "System Message", "type": "str", "info": "System message to pass to the model.", "required": false}, {"name": "temperature", "display_name": "Temperature", "type": "slider", "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.", "required": false}, {"name": "tool_model_enabled", "display_name": "Tool Model Enabled", "type": "bool", "info": "Whether to use the tool model.", "required": false}, {"name": "top_k", "display_name": "Top K", "type": "int", "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.", "required": false}, {"name": "top_p", "display_name": "Top P", "type": "float", "info": "The maximum cumulative probability of tokens to consider when sampling.", "required": false}]}
{"category": "jigsawstack", "name": "JigsawStackTextToSQL", "display_name": "Text to SQL", "description": "Convert natural language to SQL queries using JigsawStack AI", "base_classes": ["Data"], "inputs": [{"name": "api_key", "display_name": "JigsawStack API Key", "type": "str", "info": "Your JigsawStack API key for authentication", "required": true}, {"name": "file_store_key", "display_name": "File Store Key", "type": "str", "info": "The key used to store the database schema on Jigsawstack file Storage. Not required if sql_schema is specified.", "required": false}, {"name": "prompt", "display_name": "Prompt", "type": "query", "info": "Natural language description of the SQL query you want to generate", "required": true}, {"name": "sql_schema", "display_name": "SQL Schema", "type": "str", "info": "The database schema information. Can be a CREATE TABLE statement or schema description. Specifying this parameter improves SQL generation accuracy by applying database-specific syntax and optimizations.", "required": false}]}
{"category": "jigsawstack", "name": "JigsawStackFileUpload", "display_name": "File Upload", "description": "Store any file seamlessly on JigsawStack File Storage and use it in your AI applications.         Supports various file types including images, documents, and more.", "base_classes": ["Data"], "inputs": [{"name": "file", "display_name": "File", "type": "file", "info": "Upload file to be stored on JigsawStack File Storage.", "required": true}, {"name": "api_key", "display_name": "JigsawStack API Key", "type": "str", "info": "Your JigsawStack API key for authentication", "required": true}, {"name": "key", "display_name": "Key", "type": "str", "info": "The key used to store the file on JigsawStack File Storage.                 If not provided, a unique key will be generated.", "required": false}, {"name": "overwrite", "display_name": "Overwrite Existing File", "type": "bool", "info": "If true, will overwrite the existing file with the same key.                 If false, will return an error if the file already exists.", "required": false}, {"name": "temp_public_url", "display_name": "Return Temporary Public URL", "type": "bool", "info": "If true, will return a temporary public URL which lasts for a limited time.                 If false, will return the file store key which can only be accessed by the owner.", "required": false}]}